{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN76iIazpz3VfVrenWLQyw/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weichang888/AD/blob/main/%E3%80%8Cblue_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4KwkW8Jg2pZ",
        "outputId": "dd709271-3553-4593-ccee-8a7120c84ecf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###data_loader"
      ],
      "metadata": {
        "id": "PYviBwTeesnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6dS7beHAdb4C"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import glob\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, root_dir, obj_name, transform=None, resize_shape=None):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.obj_name = obj_name\n",
        "        self.resize_shape=resize_shape\n",
        "        self.image_names = sorted(glob.glob(root_dir + self.obj_name + \"/train/*/*.png\"))\n",
        "\n",
        "        if transform is not None:\n",
        "            self.transform = transform\n",
        "        else:\n",
        "            self.transform = transforms.Compose([])\n",
        "            self.transform.transforms.append(transforms.Resize((self.resize_shape, self.resize_shape)))\n",
        "            # self.transform.transforms.append(transforms.RandomHorizontalFlip())\n",
        "            # self.transform.transforms.append(transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1))\n",
        "            self.transform.transforms.append(transforms.ToTensor())\n",
        "            self.transform.transforms.append(transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                    std=[0.229, 0.224, 0.225]))\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(str(self.image_names[idx])).convert(\"RGB\")\n",
        "        img = self.transform(img)\n",
        "        return {\"image\":img}\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, root_dir, obj_name, transform=None, resize_shape=None):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.obj_name = obj_name\n",
        "        self.resize_shape=resize_shape\n",
        "        self.image_names = sorted(glob.glob(root_dir + self.obj_name + \"/test/*/*.png\"))\n",
        "        self.gt_root = \"/content/drive/My Drive/AD/datasets/MVTec/\" + self.obj_name + \"/ground_truth/\"\n",
        "\n",
        "        if transform is not None:\n",
        "            self.transform = transform\n",
        "        else:\n",
        "            # image preprocess\n",
        "            self.transform = transforms.Compose([])\n",
        "            self.transform.transforms.append(transforms.Resize((self.resize_shape, self.resize_shape)))\n",
        "            self.transform.transforms.append(transforms.ToTensor())\n",
        "            self.transform.transforms.append(transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                    std=[0.229, 0.224, 0.225]))\n",
        "            # gt preprocess\n",
        "            self.gt_transform = transforms.Compose([])\n",
        "            self.gt_transform.transforms.append(transforms.Resize((self.resize_shape, self.resize_shape)))\n",
        "            self.gt_transform.transforms.append(transforms.ToTensor())\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = str(self.image_names[idx])\n",
        "        label = img_path.split(\"/\")[-2]\n",
        "        gt_path = self.gt_root + label + \"/\" + img_path.split(\"/\")[-1][:3] + \"_mask.png\"\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        label = img_path.split(\"/\")[-2]\n",
        "        img = self.transform(img)\n",
        "\n",
        "        if label == \"good\":\n",
        "            gt_img = np.array([0], dtype=np.float32)\n",
        "            gt_pix = torch.zeros([1, self.resize_shape, self.resize_shape])\n",
        "        else:\n",
        "            gt_img = np.array([1], dtype=np.float32)\n",
        "            gt_pix = self.gt_transform(Image.open(gt_path))\n",
        "\n",
        "        return {\"image\":img, \"label\":gt_img, \"gt_mask\":gt_pix}\n",
        "\n",
        "        # good : 0, anomaly : 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###loss"
      ],
      "metadata": {
        "id": "4z1PYqOjexAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_ano_map(feature1, feature2):\n",
        "    mseloss = nn.MSELoss(reduction='none') #1*C*H*W\n",
        "    mse = mseloss(feature1, feature2) #1*C*H*W\n",
        "    mse = torch.mean(mse,dim=1) #1*H*W\n",
        "    cos = nn.functional.cosine_similarity(feature1, feature2, dim=1)\n",
        "    ano_map = torch.ones_like(cos)-cos\n",
        "    loss = (ano_map.view(ano_map.shape[0],-1).mean(-1)).mean()\n",
        "    return ano_map.unsqueeze(1), loss, mse.unsqueeze(1)\n",
        "\n",
        "class CosineLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CosineLoss, self).__init__()\n",
        "\n",
        "    def forward(self, feature1, feature2):\n",
        "        cos = nn.functional.cosine_similarity(feature1, feature2, dim=1)\n",
        "        ano_map = torch.ones_like(cos) - cos\n",
        "        loss = (ano_map.view(ano_map.shape[0],-1).mean(-1)).mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "# x1 = torch.rand(2,10,50,50)\n",
        "\n",
        "# x2 = torch.rand(2,10,50,50)\n",
        "\n",
        "# cos = CosineLoss()\n",
        "\n",
        "# print(cos(x1, x2))"
      ],
      "metadata": {
        "id": "uDnKMTWUe1qv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###model"
      ],
      "metadata": {
        "id": "1E-BzRi0e9XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import wide_resnet50_2\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channel, kernel_size, filters, stride):\n",
        "        super(ConvBlock,self).__init__()\n",
        "        F1, F2, F3 = filters\n",
        "        self.stage = nn.Sequential(\n",
        "            nn.Conv2d(in_channel,F1,1,stride=stride, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(F1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(F1,F2,kernel_size, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(F2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(F2,F3,1,stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(F3),\n",
        "        )\n",
        "        self.shortcut_1 = nn.Conv2d(in_channel, F3, 1, stride=stride, padding=0, bias=False)\n",
        "        self.batch_1 = nn.BatchNorm2d(F3)\n",
        "        self.relu_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X_shortcut = self.shortcut_1(X)\n",
        "        X_shortcut = self.batch_1(X_shortcut)\n",
        "        X = self.stage(X)\n",
        "        X = X + X_shortcut\n",
        "        X = self.relu_1(X)\n",
        "        return X\n",
        "\n",
        "class IndentityBlock(nn.Module):\n",
        "    def __init__(self, in_channel, kernel_size, filters):\n",
        "        super(IndentityBlock,self).__init__()\n",
        "        F1, F2, F3 = filters\n",
        "        self.stage = nn.Sequential(\n",
        "            nn.Conv2d(in_channel,F1,1,stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(F1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(F1,F2,kernel_size, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(F2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(F2,F3,1,stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(F3),\n",
        "        )\n",
        "        self.relu_1 = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X_shortcut = X\n",
        "        X = self.stage(X)\n",
        "        X = X + X_shortcut\n",
        "        X = self.relu_1(X)\n",
        "        return X\n",
        "\n",
        "class ConvTransposeBlock(nn.Module):\n",
        "    def __init__(self, in_channel, kernel_size, filters):\n",
        "        super(ConvTransposeBlock,self).__init__()\n",
        "        F1, F2, F3 = filters\n",
        "        self.stage = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channel,F1,kernel_size=2,stride=2, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(F1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(F1,F2,kernel_size, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(F2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(F2,F3,1,stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(F3),\n",
        "        )\n",
        "        self.shortcut_1 = nn.ConvTranspose2d(in_channel,F3,kernel_size=2,stride=2, padding=0, bias=False)\n",
        "        self.batch_1 = nn.BatchNorm2d(F3)\n",
        "        self.relu_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X_shortcut = self.shortcut_1(X)\n",
        "        X_shortcut = self.batch_1(X_shortcut)\n",
        "        X = self.stage(X)\n",
        "        X = X + X_shortcut\n",
        "        X = self.relu_1(X)\n",
        "        return X\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.wRes50 = wide_resnet50_2(pretrained=True)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.wRes50.conv1(x)\n",
        "        x = self.wRes50.bn1(x)\n",
        "        x = self.wRes50.relu(x)\n",
        "        x = self.wRes50.maxpool(x)\n",
        "\n",
        "        x = self.wRes50.layer1(x) # [1, 256, 64, 64]\n",
        "        feature1 = x\n",
        "\n",
        "        x = self.wRes50.layer2(x) # [1, 512, 32, 32]\n",
        "        feature2 = x\n",
        "\n",
        "        x = self.wRes50.layer3(x) # [1, 1024, 16, 16]\n",
        "        feature3 = x\n",
        "\n",
        "        return feature1, feature2, feature3\n",
        "\n",
        "class OCBE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OCBE, self).__init__()\n",
        "        self.branch1 = nn.Sequential(nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 2, padding = 1),\n",
        "                                     nn.BatchNorm2d(512),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     nn.Conv2d(in_channels = 512, out_channels = 1024, kernel_size = 3, stride = 2, padding = 1),\n",
        "                                     nn.BatchNorm2d(1024),\n",
        "                                     nn.ReLU(inplace=True)\n",
        "                                     )\n",
        "\n",
        "        self.branch2 = nn.Sequential(nn.Conv2d(in_channels = 512, out_channels = 1024, kernel_size = 3, stride = 2, padding = 1),\n",
        "                                     nn.BatchNorm2d(1024),\n",
        "                                     nn.ReLU(inplace=True)\n",
        "                                     )\n",
        "\n",
        "        self.merge =nn.Sequential(nn.Conv2d(in_channels = 3072, out_channels = 1024, kernel_size = 1, stride = 1, padding = 0),\n",
        "                                  nn.BatchNorm2d(1024),\n",
        "                                  nn.ReLU(inplace=True)\n",
        "                                  )\n",
        "\n",
        "        self.resblock = nn.Sequential(ConvBlock(in_channel =1024, kernel_size = 3, filters=[512,512,2048], stride=2),\n",
        "                                      IndentityBlock(in_channel=2048, kernel_size=3, filters=[512,512,2048]),\n",
        "                                      IndentityBlock(in_channel=2048, kernel_size=3, filters=[512,512,2048])\n",
        "                                      )\n",
        "\n",
        "    def forward(self, x1, x2, x3):\n",
        "        output = torch.cat((self.branch1(x1),self.branch2(x2),x3),dim=1) # [1, 3072, 16, 16]\n",
        "        output = self.merge(output) # [1, 1024, 16, 16]\n",
        "        # output = self.branch1(x1) + self.branch2(x2) + x3\n",
        "        output = self.resblock(output) # [1, 2048, 8, 8]\n",
        "\n",
        "        return output\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layer3 = nn.Sequential(ConvTransposeBlock(in_channel=2048, kernel_size=3, filters=[512, 1024, 1024]),\n",
        "                                    IndentityBlock(in_channel=1024, kernel_size=3, filters=[512,1024,1024]),\n",
        "                                    IndentityBlock(in_channel=1024, kernel_size=3, filters=[512,1024,1024]),\n",
        "                                    IndentityBlock(in_channel=1024, kernel_size=3, filters=[512,1024,1024]),\n",
        "                                    IndentityBlock(in_channel=1024, kernel_size=3, filters=[512,1024,1024]),\n",
        "                                    IndentityBlock(in_channel=1024, kernel_size=3, filters=[512,1024,1024]),\n",
        "                                    )\n",
        "        self.layer2 = nn.Sequential(ConvTransposeBlock(in_channel=1024, kernel_size=3, filters=[256, 512, 512]),\n",
        "                                    IndentityBlock(in_channel=512, kernel_size=3, filters=[256, 512, 512]),\n",
        "                                    IndentityBlock(in_channel=512, kernel_size=3, filters=[256, 512, 512]),\n",
        "                                    IndentityBlock(in_channel=512, kernel_size=3, filters=[256, 512, 512])\n",
        "                                    )\n",
        "        self.layer1 = nn.Sequential(ConvTransposeBlock(in_channel=512, kernel_size=3, filters=[128, 256, 256]),\n",
        "                                    IndentityBlock(in_channel=256, kernel_size=3, filters=[128, 256, 256]),\n",
        "                                    IndentityBlock(in_channel=256, kernel_size=3, filters=[128, 256, 256])\n",
        "                                    )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer3(x) # [1, 1024, 14, 14]\n",
        "        feature3 = x\n",
        "        x = self.layer2(x) # [1, 512, 28, 28]\n",
        "        feature2 = x\n",
        "        x = self.layer1(x) # [1, 256, 56, 56]\n",
        "        feature1 = x\n",
        "\n",
        "        return feature1, feature2, feature3\n",
        "\n",
        "class OcbeAndDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OcbeAndDecoder, self).__init__()\n",
        "        self.ocbe = OCBE()\n",
        "        self.decoder = Decoder()\n",
        "    def forward(self, e_feature1, e_feature2, e_feature3):\n",
        "        x = self.ocbe(e_feature1, e_feature2, e_feature3)\n",
        "        feature1, feature2, feature3 = self.decoder(x)\n",
        "        return feature1, feature2, feature3"
      ],
      "metadata": {
        "id": "Jm9LZBc6e3OI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###test"
      ],
      "metadata": {
        "id": "JOC2aCesfF79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyDn0CUW_bFt",
        "outputId": "2c4c8e6b-a476-41b7-9f58-efc90f066361"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "def get_ano_map(feature1, feature2):\n",
        "    mseloss = nn.MSELoss(reduction='none')\n",
        "    mse = mseloss(feature1, feature2)\n",
        "    mse = torch.mean(mse, dim=1)\n",
        "    cos = nn.functional.cosine_similarity(feature1, feature2, dim=1)\n",
        "    ano_map = torch.ones_like(cos) - cos\n",
        "    loss = (ano_map.view(ano_map.shape[0], -1).mean(-1)).mean()\n",
        "    return ano_map.unsqueeze(1), loss, mse.unsqueeze(1)\n",
        "\n",
        "def save_image(image, ano_map, gt_mask, output_dir, idx):\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    to_pil = ToPILImage()\n",
        "    ax[0].imshow(to_pil(image.cpu()))\n",
        "    ax[0].set_title(\"Original Image\")\n",
        "\n",
        "    # 使用适当的 colormap 和插值方式\n",
        "    ax[1].imshow(ano_map.cpu().numpy().squeeze(), cmap='jet', interpolation='bilinear')\n",
        "    ax[1].set_title(\"Anomaly Map\")\n",
        "\n",
        "    ax[2].imshow(gt_mask.cpu().numpy().squeeze(), cmap='gray', interpolation='bilinear')\n",
        "    ax[2].set_title(\"Ground Truth Mask\")\n",
        "\n",
        "    plt.savefig(os.path.join(output_dir, f\"prediction_{idx}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def test(obj_name, ckp_dir, data_dir, reshape_size, output_dir):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    encoder = Encoder()\n",
        "    encoder.to(device)\n",
        "    ocbe_decoder = OcbeAndDecoder()\n",
        "\n",
        "    ocbe_decoder.load_state_dict(torch.load(str(ckp_dir), map_location='cpu'))\n",
        "    ocbe_decoder.to(device)\n",
        "\n",
        "    encoder.eval()\n",
        "    ocbe_decoder.eval()\n",
        "\n",
        "    test_dataset = TestDataset(root_dir=data_dir, obj_name=obj_name, resize_shape=reshape_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    test_loss_total = 0\n",
        "    scores = []\n",
        "    labels = []\n",
        "    gt_list_px = []\n",
        "    pr_list_px = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, sample_test in enumerate(test_loader):\n",
        "            image, label, gt = sample_test[\"image\"], sample_test[\"label\"], sample_test[\"gt_mask\"]\n",
        "\n",
        "            gt[gt > 0.5] = 1\n",
        "            gt[gt <= 0.5] = 0\n",
        "\n",
        "            e_feature1, e_feature2, e_feature3 = encoder(image.to(device))\n",
        "            d_feature1, d_feature2, d_feature3 = ocbe_decoder(e_feature1, e_feature2, e_feature3)\n",
        "\n",
        "            ano_map1, loss1, mse1 = get_ano_map(e_feature1, d_feature1)\n",
        "            ano_map2, loss2, mse2 = get_ano_map(e_feature2, d_feature2)\n",
        "            ano_map3, loss3, mse3 = get_ano_map(e_feature3, d_feature3)\n",
        "\n",
        "            ano_map1 = nn.functional.interpolate(ano_map1, size=(reshape_size, reshape_size), mode='bilinear', align_corners=True)\n",
        "            ano_map2 = nn.functional.interpolate(ano_map2, size=(reshape_size, reshape_size), mode='bilinear', align_corners=True)\n",
        "            ano_map3 = nn.functional.interpolate(ano_map3, size=(reshape_size, reshape_size), mode='bilinear', align_corners=True)\n",
        "            s_al = (ano_map1 + ano_map2 + ano_map3).squeeze().cpu().numpy()\n",
        "\n",
        "            s_al = gaussian_filter(s_al, sigma=2)  # 调整 sigma 参数\n",
        "\n",
        "            gt_list_px.extend(gt.cpu().numpy().astype(int).ravel())\n",
        "            pr_list_px.extend(s_al.ravel())\n",
        "\n",
        "            score = np.max(s_al.ravel().tolist())\n",
        "\n",
        "            scores.append(score)\n",
        "            labels.append(label.numpy().squeeze())\n",
        "\n",
        "            loss = loss1.item() + loss2.item() + loss3.item()\n",
        "            test_loss_total += loss\n",
        "\n",
        "            save_image(image[0], torch.tensor(s_al), gt[0], output_dir, idx)\n",
        "\n",
        "    auroc_img = round(roc_auc_score(np.array(labels), np.array(scores)), 3)\n",
        "    auroc_pix = round(roc_auc_score(np.array(gt_list_px), np.array(pr_list_px)), 3)\n",
        "    return test_loss_total, auroc_img, auroc_pix\n",
        "\n"
      ],
      "metadata": {
        "id": "63XK43SZfHnO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###train"
      ],
      "metadata": {
        "id": "6bdjwrIcfIS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "# 以下导入部分假设您已经定义或安装了必要的模块和类\n",
        "# from data_loader import TrainDataset\n",
        "# from model import Encoder, OcbeAndDecoder\n",
        "# from loss import CosineLoss\n",
        "# from test import test\n",
        "\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.obj_id = 0  # 指定对象ID\n",
        "        self.bs = 16  # 批处理大小\n",
        "        self.lr = 0.005  # 学习率\n",
        "        self.epochs = 200  # 迭代次数\n",
        "        self.gpu_id = 0  # GPU ID\n",
        "        self.data_path = \"/content/drive/My Drive/AD/datasets/MVTec/\"  # 数据路径\n",
        "        self.checkpoint_path = \"/content/drive/My Drive/AD/checkpoints/\"  # 检查点保存路径\n",
        "        self.test_interval = 5  # 测试间隔\n",
        "\n",
        "def train(obj_name, args):\n",
        "    resize_shape = 256\n",
        "    print(f\"Start training {obj_name}\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if not os.path.exists(args.checkpoint_path):\n",
        "        os.makedirs(args.checkpoint_path)\n",
        "\n",
        "    cur_time = f\"{datetime.datetime.now():%Y-%m-%d_%H_%M_%S}\"\n",
        "    run_time = f\"{obj_name}_lr{args.lr}_bs{args.bs}_{cur_time}\"\n",
        "    writer = SummaryWriter(log_dir=f\"/content/drive/My Drive/AD/logs/WRes50/{run_time}/\")\n",
        "    os.makedirs(f\"/content/drive/My Drive/AD/checkpoints/WRes50/{run_time}\", exist_ok=True)\n",
        "\n",
        "    encoder = Encoder()\n",
        "    ocbe_decoder = OcbeAndDecoder()\n",
        "    encoder.to(device)\n",
        "    ocbe_decoder.to(device)\n",
        "    encoder.eval()\n",
        "\n",
        "    train_dataset = TrainDataset(root_dir=args.data_path, obj_name=obj_name, resize_shape=resize_shape)\n",
        "    print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "    if len(train_dataset) == 0:\n",
        "        raise ValueError(\"The training dataset is empty. Please check the dataset path and contents.\")\n",
        "\n",
        "    # 将 num_workers 设置为 2\n",
        "    train_loader = DataLoader(train_dataset, batch_size=args.bs, shuffle=True, drop_last=True, num_workers=2, persistent_workers=True, pin_memory=True, prefetch_factor=2)\n",
        "\n",
        "    mse = nn.MSELoss()\n",
        "    cos_similarity = CosineLoss()\n",
        "    optimizer = torch.optim.Adam(ocbe_decoder.parameters(), betas=(0.5, 0.999), lr=args.lr)\n",
        "\n",
        "    auroc_img_best, img_step = 0, 0\n",
        "    auroc_pix_best, pix_step = 0, 0\n",
        "\n",
        "    for step in tqdm(range(args.epochs), ascii=True):\n",
        "        ocbe_decoder.train()\n",
        "        train_loss_total = 0\n",
        "        for idx, sample in enumerate(train_loader):\n",
        "            images = sample[\"image\"].to(device)\n",
        "\n",
        "            e_feature1, e_feature2, e_feature3 = encoder(images)\n",
        "            d_feature1, d_feature2, d_feature3 = ocbe_decoder(e_feature1, e_feature2, e_feature3)\n",
        "\n",
        "            loss1 = cos_similarity(e_feature1, d_feature1)\n",
        "            loss2 = cos_similarity(e_feature2, d_feature2)\n",
        "            loss3 = cos_similarity(e_feature3, d_feature3)\n",
        "            loss = loss1 + loss2 + loss3\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_total += loss.item()\n",
        "\n",
        "        writer.add_scalar(\"train_loss\", train_loss_total, step)\n",
        "\n",
        "        if args.test_interval > 0 and step % args.test_interval == 0:\n",
        "            ckp_path = f\"{args.checkpoint_path}WRes50/{run_time}/epoch{step}.pth\"\n",
        "            torch.save(ocbe_decoder.state_dict(), ckp_path)\n",
        "            output_dir = f\"/content/drive/My Drive/AD/predict/{obj_name}/{step}/\"\n",
        "            test_loss, auroc_img, auroc_pix = test(obj_name=obj_name, ckp_dir=ckp_path, data_dir=args.data_path, reshape_size=resize_shape, output_dir=output_dir)\n",
        "            writer.add_scalar(\"test_loss\", test_loss, step)\n",
        "            writer.add_scalar(\"auroc_img\", auroc_img, step)\n",
        "            writer.add_scalar(\"auroc_pix\", auroc_pix, step)\n",
        "\n",
        "            if auroc_img <= auroc_img_best and auroc_pix <= auroc_pix_best:\n",
        "                os.remove(ckp_path)\n",
        "\n",
        "            if auroc_img > auroc_img_best:\n",
        "                auroc_img_best = auroc_img\n",
        "                img_step = step\n",
        "            if auroc_pix > auroc_pix_best:\n",
        "                auroc_pix_best = auroc_pix\n",
        "                pix_step = step\n",
        "\n",
        "    return run_time, auroc_img_best, auroc_pix_best, img_step, pix_step\n",
        "\n",
        "def write2txt(filename, content):\n",
        "    with open(filename, 'a') as f:\n",
        "        f.write(str(content) + \"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    class Args:\n",
        "        def __init__(self):\n",
        "            self.obj_id = 0  # 指定对象ID\n",
        "            self.bs = 16  # 批处理大小\n",
        "            self.lr = 0.005  # 学习率\n",
        "            self.epochs = 200  # 迭代次数\n",
        "            self.gpu_id = 0  # GPU ID\n",
        "            self.data_path = \"/content/drive/My Drive/AD/datasets/MVTec/\"  # 数据路径\n",
        "            self.checkpoint_path = \"/content/drive/My Drive/AD/checkpoints/\"  # 检查点保存路径\n",
        "            self.test_interval = 5  # 测试间隔\n",
        "\n",
        "    args = Args()\n",
        "\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_id)\n",
        "    obj_names = [\n",
        "        'bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut',\n",
        "        'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush',\n",
        "        'transistor', 'wood', 'zipper'\n",
        "    ]\n",
        "\n",
        "    log_txt_name = f\"/content/drive/My Drive/AD/logs_txt/{datetime.datetime.now():%Y-%m-%d_%H_%M_%S}.txt\"\n",
        "    os.makedirs(os.path.dirname(log_txt_name), exist_ok=True)\n",
        "\n",
        "    write2txt(log_txt_name, \"log title\")\n",
        "    if args.obj_id == -1:\n",
        "        for obj_name in obj_names:\n",
        "            print(f\"Training for category: {obj_name}\")\n",
        "            model_name, auroc_img_best, auroc_pix_best, img_step, pix_step = train(obj_name, args)\n",
        "            write2txt(log_txt_name, f\"{model_name} || auroc_img: {auroc_img_best} epoch: {img_step} || auroc_pix: {auroc_pix_best} epoch: {pix_step}\")\n",
        "    else:\n",
        "        obj_name = obj_names[int(args.obj_id)]\n",
        "        print(f\"Training for category: {obj_name}\")\n",
        "        model_name, auroc_img_best, auroc_pix_best, img_step, pix_step = train(obj_name, args)\n",
        "        write2txt(log_txt_name, f\"{model_name} || auroc_img: {auroc_img_best} epoch: {img_step} || auroc_pix: {auroc_pix_best} epoch: {pix_step}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhRAvbcVm9Uc",
        "outputId": "00757af6-4079-4b19-9bb4-42b2660ef5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for category: bottle\n",
            "Start training bottle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n",
            "100%|██████████| 132M/132M [00:00<00:00, 197MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "  2%|2         | 5/200 [03:45<1:10:52, 21.81s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "  5%|5         | 10/200 [04:52<31:45, 10.03s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "  8%|7         | 15/200 [06:00<25:58,  8.43s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 10%|#         | 20/200 [07:08<24:28,  8.16s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 12%|#2        | 25/200 [08:15<23:40,  8.12s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 15%|#5        | 30/200 [09:22<22:37,  7.98s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 18%|#7        | 35/200 [10:29<22:14,  8.09s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 20%|##        | 40/200 [11:38<21:45,  8.16s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 22%|##2       | 45/200 [12:44<20:39,  7.99s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 25%|##5       | 50/200 [13:52<20:18,  8.12s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 28%|##7       | 55/200 [14:59<19:19,  8.00s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 30%|###       | 60/200 [16:06<18:47,  8.06s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 32%|###2      | 65/200 [17:15<18:28,  8.21s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 35%|###5      | 70/200 [18:22<17:23,  8.03s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 38%|###7      | 75/200 [19:28<16:38,  7.99s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 40%|####      | 80/200 [20:38<16:33,  8.28s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 42%|####2     | 85/200 [21:44<15:21,  8.01s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 45%|####5     | 90/200 [22:50<14:32,  7.94s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 48%|####7     | 95/200 [23:56<13:52,  7.93s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 50%|#####     | 100/200 [25:08<13:57,  8.37s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 52%|#####2    | 105/200 [26:14<12:42,  8.03s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 55%|#####5    | 110/200 [27:21<12:02,  8.02s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 57%|#####7    | 115/200 [28:27<11:17,  7.97s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 60%|######    | 120/200 [29:33<10:34,  7.94s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 62%|######2   | 125/200 [30:46<10:30,  8.41s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 65%|######5   | 130/200 [31:52<09:23,  8.04s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 68%|######7   | 135/200 [32:58<08:40,  8.00s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 70%|#######   | 140/200 [34:06<08:02,  8.05s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 72%|#######2  | 145/200 [35:12<07:18,  7.96s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 75%|#######5  | 150/200 [36:18<06:37,  7.96s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 78%|#######7  | 155/200 [37:33<06:26,  8.60s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 80%|########  | 160/200 [38:39<05:23,  8.09s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 82%|########2 | 165/200 [39:45<04:39,  7.98s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            " 85%|########5 | 170/200 [40:51<04:00,  8.00s/it]/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    }
  ]
}